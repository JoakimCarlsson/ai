package model

const (
	ProviderOpenRouter ModelProvider = "openrouter"

	OpenRouterGPT41             ModelID = "openrouter.gpt-4.1"
	OpenRouterGPT41Mini         ModelID = "openrouter.gpt-4.1-mini"
	OpenRouterGPT41Nano         ModelID = "openrouter.gpt-4.1-nano"
	OpenRouterGPT4o             ModelID = "openrouter.gpt-4o"
	OpenRouterGPT4oMini         ModelID = "openrouter.gpt-4o-mini"
	OpenRouterO1                ModelID = "openrouter.o1"
	OpenRouterO1Pro             ModelID = "openrouter.o1-pro"
	OpenRouterO1Mini            ModelID = "openrouter.o1-mini"
	OpenRouterO3                ModelID = "openrouter.o3"
	OpenRouterO3Pro             ModelID = "openrouter.o3-pro"
	OpenRouterO3Mini            ModelID = "openrouter.o3-mini"
	OpenRouterO4Mini            ModelID = "openrouter.o4-mini"
	OpenRouterGPT52             ModelID = "openrouter.gpt-5.2"
	OpenRouterGPT52Pro          ModelID = "openrouter.gpt-5.2-pro"
	OpenRouterGPT52Instant      ModelID = "openrouter.gpt-5.2-instant"
	OpenRouterGemini3Pro        ModelID = "openrouter.gemini-3-pro"
	OpenRouterGemini25Flash     ModelID = "openrouter.gemini-2.5-flash"
	OpenRouterGemini25FlashLite ModelID = "openrouter.gemini-2.5-flash-lite"
	OpenRouterGemini25          ModelID = "openrouter.gemini-2.5"
	OpenRouterClaude35Sonnet    ModelID = "openrouter.claude-3.5-sonnet"
	OpenRouterClaude3Haiku      ModelID = "openrouter.claude-3-haiku"
	OpenRouterClaude35Haiku     ModelID = "openrouter.claude-3.5-haiku"
	OpenRouterClaude3Opus       ModelID = "openrouter.claude-3-opus"
	OpenRouterClaude45Opus      ModelID = "openrouter.claude-4.5-opus"
)

var OpenRouterModels = map[ModelID]Model{
	OpenRouterGPT41: {
		ID:                    OpenRouterGPT41,
		Name:                  "OpenRouter – GPT 4.1",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-4.1",
		CostPer1MIn:           OpenAIModels[GPT41].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT41].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT41].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT41].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT41].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT41].DefaultMaxTokens,
		SupportsStructuredOut: OpenAIModels[GPT41].SupportsStructuredOut,
	},
	OpenRouterGPT41Mini: {
		ID:                    OpenRouterGPT41Mini,
		Name:                  "OpenRouter – GPT 4.1 mini",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-4.1-mini",
		CostPer1MIn:           OpenAIModels[GPT41Mini].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT41Mini].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT41Mini].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT41Mini].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT41Mini].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT41Mini].DefaultMaxTokens,
		SupportsStructuredOut: OpenAIModels[GPT41Mini].SupportsStructuredOut,
	},
	OpenRouterGPT41Nano: {
		ID:                    OpenRouterGPT41Nano,
		Name:                  "OpenRouter – GPT 4.1 nano",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-4.1-nano",
		CostPer1MIn:           OpenAIModels[GPT41Nano].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT41Nano].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT41Nano].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT41Nano].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT41Nano].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT41Nano].DefaultMaxTokens,
		SupportsStructuredOut: OpenAIModels[GPT41Nano].SupportsStructuredOut,
	},
	OpenRouterGPT4o: {
		ID:                    OpenRouterGPT4o,
		Name:                  "OpenRouter – GPT 4o",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-4o",
		CostPer1MIn:           OpenAIModels[GPT4o].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT4o].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT4o].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT4o].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT4o].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT4o].DefaultMaxTokens,
		SupportsStructuredOut: OpenAIModels[GPT4o].SupportsStructuredOut,
	},
	OpenRouterGPT4oMini: {
		ID:                    OpenRouterGPT4oMini,
		Name:                  "OpenRouter – GPT 4o mini",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-4o-mini",
		CostPer1MIn:           OpenAIModels[GPT4oMini].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT4oMini].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT4oMini].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT4oMini].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT4oMini].ContextWindow,
		SupportsStructuredOut: OpenAIModels[GPT4oMini].SupportsStructuredOut,
	},
	OpenRouterO1: {
		ID:                    OpenRouterO1,
		Name:                  "OpenRouter – O1",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o1",
		CostPer1MIn:           OpenAIModels[O1].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O1].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O1].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O1].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O1].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O1].DefaultMaxTokens,
		CanReason:             OpenAIModels[O1].CanReason,
		SupportsStructuredOut: OpenAIModels[O1].SupportsStructuredOut,
	},
	OpenRouterO1Pro: {
		ID:                    OpenRouterO1Pro,
		Name:                  "OpenRouter – o1 pro",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o1-pro",
		CostPer1MIn:           OpenAIModels[O1Pro].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O1Pro].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O1Pro].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O1Pro].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O1Pro].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O1Pro].DefaultMaxTokens,
		CanReason:             OpenAIModels[O1Pro].CanReason,
		SupportsStructuredOut: OpenAIModels[O1Pro].SupportsStructuredOut,
	},
	OpenRouterO1Mini: {
		ID:                    OpenRouterO1Mini,
		Name:                  "OpenRouter – o1 mini",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o1-mini",
		CostPer1MIn:           OpenAIModels[O1Mini].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O1Mini].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O1Mini].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O1Mini].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O1Mini].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O1Mini].DefaultMaxTokens,
		CanReason:             OpenAIModels[O1Mini].CanReason,
		SupportsStructuredOut: OpenAIModels[O1Mini].SupportsStructuredOut,
	},
	OpenRouterO3: {
		ID:                    OpenRouterO3,
		Name:                  "OpenRouter – o3",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o3",
		CostPer1MIn:           OpenAIModels[O3].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O3].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O3].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O3].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O3].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O3].DefaultMaxTokens,
		CanReason:             OpenAIModels[O3].CanReason,
		SupportsStructuredOut: OpenAIModels[O3].SupportsStructuredOut,
	},
	OpenRouterO3Mini: {
		ID:                    OpenRouterO3Mini,
		Name:                  "OpenRouter – o3 mini",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o3-mini-high",
		CostPer1MIn:           OpenAIModels[O3Mini].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O3Mini].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O3Mini].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O3Mini].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O3Mini].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O3Mini].DefaultMaxTokens,
		CanReason:             OpenAIModels[O3Mini].CanReason,
		SupportsStructuredOut: OpenAIModels[O3Mini].SupportsStructuredOut,
	},
	OpenRouterO4Mini: {
		ID:                    OpenRouterO4Mini,
		Name:                  "OpenRouter – o4 mini",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o4-mini-high",
		CostPer1MIn:           OpenAIModels[O4Mini].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O4Mini].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O4Mini].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O4Mini].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O4Mini].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O4Mini].DefaultMaxTokens,
		CanReason:             OpenAIModels[O4Mini].CanReason,
		SupportsStructuredOut: OpenAIModels[O4Mini].SupportsStructuredOut,
	},
	OpenRouterO3Pro: {
		ID:                    OpenRouterO3Pro,
		Name:                  "OpenRouter – o3 pro",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/o3-pro",
		CostPer1MIn:           OpenAIModels[O3Pro].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[O3Pro].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[O3Pro].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[O3Pro].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[O3Pro].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[O3Pro].DefaultMaxTokens,
		CanReason:             OpenAIModels[O3Pro].CanReason,
		SupportsStructuredOut: OpenAIModels[O3Pro].SupportsStructuredOut,
	},
	OpenRouterGPT52: {
		ID:                    OpenRouterGPT52,
		Name:                  "OpenRouter – GPT-5.2",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-5.2",
		CostPer1MIn:           OpenAIModels[GPT52].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT52].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT52].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT52].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT52].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT52].DefaultMaxTokens,
		CanReason:             OpenAIModels[GPT52].CanReason,
		SupportsStructuredOut: OpenAIModels[GPT52].SupportsStructuredOut,
	},
	OpenRouterGPT52Pro: {
		ID:                    OpenRouterGPT52Pro,
		Name:                  "OpenRouter – GPT-5.2 Pro",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-5.2-pro",
		CostPer1MIn:           OpenAIModels[GPT52Pro].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT52Pro].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT52Pro].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT52Pro].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT52Pro].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT52Pro].DefaultMaxTokens,
		CanReason:             OpenAIModels[GPT52Pro].CanReason,
		SupportsStructuredOut: OpenAIModels[GPT52Pro].SupportsStructuredOut,
	},
	OpenRouterGPT52Instant: {
		ID:                    OpenRouterGPT52Instant,
		Name:                  "OpenRouter – GPT-5.2 Instant",
		Provider:              ProviderOpenRouter,
		APIModel:              "openai/gpt-5.2-chat-latest",
		CostPer1MIn:           OpenAIModels[GPT52Instant].CostPer1MIn,
		CostPer1MInCached:     OpenAIModels[GPT52Instant].CostPer1MInCached,
		CostPer1MOut:          OpenAIModels[GPT52Instant].CostPer1MOut,
		CostPer1MOutCached:    OpenAIModels[GPT52Instant].CostPer1MOutCached,
		ContextWindow:         OpenAIModels[GPT52Instant].ContextWindow,
		DefaultMaxTokens:      OpenAIModels[GPT52Instant].DefaultMaxTokens,
		CanReason:             OpenAIModels[GPT52Instant].CanReason,
		SupportsStructuredOut: OpenAIModels[GPT52Instant].SupportsStructuredOut,
	},
	OpenRouterGemini25Flash: {
		ID:                    OpenRouterGemini25Flash,
		Name:                  "OpenRouter – Gemini 2.5 Flash",
		Provider:              ProviderOpenRouter,
		APIModel:              "google/gemini-2.5-flash",
		CostPer1MIn:           GeminiModels[Gemini25Flash].CostPer1MIn,
		CostPer1MInCached:     GeminiModels[Gemini25Flash].CostPer1MInCached,
		CostPer1MOut:          GeminiModels[Gemini25Flash].CostPer1MOut,
		CostPer1MOutCached:    GeminiModels[Gemini25Flash].CostPer1MOutCached,
		ContextWindow:         GeminiModels[Gemini25Flash].ContextWindow,
		DefaultMaxTokens:      GeminiModels[Gemini25Flash].DefaultMaxTokens,
		SupportsStructuredOut: GeminiModels[Gemini25Flash].SupportsStructuredOut,
	},
	OpenRouterGemini25: {
		ID:                    OpenRouterGemini25,
		Name:                  "OpenRouter – Gemini 2.5 Pro",
		Provider:              ProviderOpenRouter,
		APIModel:              "google/gemini-2.5-pro",
		CostPer1MIn:           GeminiModels[Gemini25].CostPer1MIn,
		CostPer1MInCached:     GeminiModels[Gemini25].CostPer1MInCached,
		CostPer1MOut:          GeminiModels[Gemini25].CostPer1MOut,
		CostPer1MOutCached:    GeminiModels[Gemini25].CostPer1MOutCached,
		ContextWindow:         GeminiModels[Gemini25].ContextWindow,
		DefaultMaxTokens:      GeminiModels[Gemini25].DefaultMaxTokens,
		SupportsStructuredOut: GeminiModels[Gemini25].SupportsStructuredOut,
	},
	OpenRouterGemini3Pro: {
		ID:                    OpenRouterGemini3Pro,
		Name:                  "OpenRouter – Gemini 3 Pro",
		Provider:              ProviderOpenRouter,
		APIModel:              "google/gemini-3-pro",
		CostPer1MIn:           GeminiModels[Gemini3Pro].CostPer1MIn,
		CostPer1MInCached:     GeminiModels[Gemini3Pro].CostPer1MInCached,
		CostPer1MOut:          GeminiModels[Gemini3Pro].CostPer1MOut,
		CostPer1MOutCached:    GeminiModels[Gemini3Pro].CostPer1MOutCached,
		ContextWindow:         GeminiModels[Gemini3Pro].ContextWindow,
		DefaultMaxTokens:      GeminiModels[Gemini3Pro].DefaultMaxTokens,
		CanReason:             GeminiModels[Gemini3Pro].CanReason,
		SupportsStructuredOut: GeminiModels[Gemini3Pro].SupportsStructuredOut,
	},
	OpenRouterGemini25FlashLite: {
		ID:                    OpenRouterGemini25FlashLite,
		Name:                  "OpenRouter – Gemini 2.5 Flash Lite",
		Provider:              ProviderOpenRouter,
		APIModel:              "google/gemini-2.5-flash-lite",
		CostPer1MIn:           GeminiModels[Gemini25FlashLite].CostPer1MIn,
		CostPer1MInCached:     GeminiModels[Gemini25FlashLite].CostPer1MInCached,
		CostPer1MOut:          GeminiModels[Gemini25FlashLite].CostPer1MOut,
		CostPer1MOutCached:    GeminiModels[Gemini25FlashLite].CostPer1MOutCached,
		ContextWindow:         GeminiModels[Gemini25FlashLite].ContextWindow,
		DefaultMaxTokens:      GeminiModels[Gemini25FlashLite].DefaultMaxTokens,
		SupportsStructuredOut: GeminiModels[Gemini25FlashLite].SupportsStructuredOut,
	},
	OpenRouterClaude35Sonnet: {
		ID:                    OpenRouterClaude35Sonnet,
		Name:                  "OpenRouter – Claude 3.5 Sonnet",
		Provider:              ProviderOpenRouter,
		APIModel:              "anthropic/claude-3.5-sonnet",
		CostPer1MIn:           AnthropicModels[Claude35Sonnet].CostPer1MIn,
		CostPer1MInCached:     AnthropicModels[Claude35Sonnet].CostPer1MInCached,
		CostPer1MOut:          AnthropicModels[Claude35Sonnet].CostPer1MOut,
		CostPer1MOutCached:    AnthropicModels[Claude35Sonnet].CostPer1MOutCached,
		ContextWindow:         AnthropicModels[Claude35Sonnet].ContextWindow,
		DefaultMaxTokens:      AnthropicModels[Claude35Sonnet].DefaultMaxTokens,
		SupportsStructuredOut: false,
	},
	OpenRouterClaude3Haiku: {
		ID:                    OpenRouterClaude3Haiku,
		Name:                  "OpenRouter – Claude 3 Haiku",
		Provider:              ProviderOpenRouter,
		APIModel:              "anthropic/claude-3-haiku",
		CostPer1MIn:           AnthropicModels[Claude3Haiku].CostPer1MIn,
		CostPer1MInCached:     AnthropicModels[Claude3Haiku].CostPer1MInCached,
		CostPer1MOut:          AnthropicModels[Claude3Haiku].CostPer1MOut,
		CostPer1MOutCached:    AnthropicModels[Claude3Haiku].CostPer1MOutCached,
		ContextWindow:         AnthropicModels[Claude3Haiku].ContextWindow,
		DefaultMaxTokens:      AnthropicModels[Claude3Haiku].DefaultMaxTokens,
		SupportsStructuredOut: false,
	},
	OpenRouterClaude35Haiku: {
		ID:                    OpenRouterClaude35Haiku,
		Name:                  "OpenRouter – Claude 3.5 Haiku",
		Provider:              ProviderOpenRouter,
		APIModel:              "anthropic/claude-3.5-haiku",
		CostPer1MIn:           AnthropicModels[Claude35Haiku].CostPer1MIn,
		CostPer1MInCached:     AnthropicModels[Claude35Haiku].CostPer1MInCached,
		CostPer1MOut:          AnthropicModels[Claude35Haiku].CostPer1MOut,
		CostPer1MOutCached:    AnthropicModels[Claude35Haiku].CostPer1MOutCached,
		ContextWindow:         AnthropicModels[Claude35Haiku].ContextWindow,
		DefaultMaxTokens:      AnthropicModels[Claude35Haiku].DefaultMaxTokens,
		SupportsStructuredOut: false,
	},
	OpenRouterClaude3Opus: {
		ID:                    OpenRouterClaude3Opus,
		Name:                  "OpenRouter – Claude 3 Opus",
		Provider:              ProviderOpenRouter,
		APIModel:              "anthropic/claude-3-opus",
		CostPer1MIn:           AnthropicModels[Claude3Opus].CostPer1MIn,
		CostPer1MInCached:     AnthropicModels[Claude3Opus].CostPer1MInCached,
		CostPer1MOut:          AnthropicModels[Claude3Opus].CostPer1MOut,
		CostPer1MOutCached:    AnthropicModels[Claude3Opus].CostPer1MOutCached,
		ContextWindow:         AnthropicModels[Claude3Opus].ContextWindow,
		DefaultMaxTokens:      AnthropicModels[Claude3Opus].DefaultMaxTokens,
		SupportsStructuredOut: false,
	},
	OpenRouterClaude45Opus: {
		ID:                    OpenRouterClaude45Opus,
		Name:                  "OpenRouter – Claude 4.5 Opus",
		Provider:              ProviderOpenRouter,
		APIModel:              "anthropic/claude-opus-4-5-20251101",
		CostPer1MIn:           AnthropicModels[Claude45Opus].CostPer1MIn,
		CostPer1MInCached:     AnthropicModels[Claude45Opus].CostPer1MInCached,
		CostPer1MOut:          AnthropicModels[Claude45Opus].CostPer1MOut,
		CostPer1MOutCached:    AnthropicModels[Claude45Opus].CostPer1MOutCached,
		ContextWindow:         AnthropicModels[Claude45Opus].ContextWindow,
		DefaultMaxTokens:      AnthropicModels[Claude45Opus].DefaultMaxTokens,
		CanReason:             AnthropicModels[Claude45Opus].CanReason,
		SupportsStructuredOut: false,
	},
}
